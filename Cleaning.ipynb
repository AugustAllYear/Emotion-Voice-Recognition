{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a277e2-6d42-46bc-b4a3-e664318a7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf2a50-ad89-4614-b79b-dfeb588d405c",
   "metadata": {},
   "source": [
    "*KaggleHub is a Python package that provides a simple API to access Kaggle resources anywhere, including Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650b3f29-78bb-432e-880b-1563f0ff1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (0.7.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.12 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: six>=1.3 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (1.17.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (0.4.3)\n",
      "Requirement already satisfied: numba>=0.43.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from numba>=0.43.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from soundfile>=0.9.0->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/augustvollbrecht/virtual/evr/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a102823e-14de-483f-be88-8ba5b177809f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# !pip install librosa\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m    \n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "# !pip install librosa\n",
    "import librosa\n",
    "import pandas as pd    \n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d171ca4-d65d-4d20-a8bc-006abcac223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/augustvollbrecht/.cache/kagglehub/datasets/uwrfkaggler/ravdess-emotional-speech-audio/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf329ce6-e4dd-4654-913f-2d88e3ce3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "single_file1 = (path + '03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb03813-46e6-43b4-b4d5-292bd4bc61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_file2 = (path + '03-01-01-01-01-02-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91184d6-cc46-4247-8923-3c6c83cb3938",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y, sr = \u001b[43mlibrosa\u001b[49m.load(single_file1, sr=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(single_file1, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ad2680-4b1b-4bed-bea6-506357a37ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y, sr = \u001b[43mlibrosa\u001b[49m.load(single_file2, sr=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(single_file2, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b6a1c-277b-44d4-be26-5683a2cc18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to decibles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf163b1-8d24-44d5-a155-73929a803d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Digital signal from Analog signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6cc68-f831-43d8-a537-ab7fd3e5a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate amplitude over time or amplitude over frequencey\n",
    "Time-domain analysis fails to represent frequencey as feature \n",
    "where frequencey-domain dosnt illusttrate time.\n",
    "\n",
    "    \n",
    "Visualizing to help us see relationships consecutively.\n",
    "\n",
    "librosa will help us extract these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ec1df-4d65-4ae9-a853-2c6c607ed797",
   "metadata": {},
   "source": [
    "Two potential renderings of our audio data files are\n",
    "Mel-Frequencey Cepstral Coefficients and raw Audiowaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3cd12-9b7f-4017-8dba-a229aeb299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sample audio wave spectograms of select datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b285f5-ae3d-4bb8-adf8-93806fa892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all of the data: \n",
    "# 1. Ensure its all the same size # for the model: Normalie\n",
    "# 2. Take the mean to conserve processing power\n",
    "# this allows us to use sample from multiple datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760c824-c1ea-4840-88f1-5772c63b6be9",
   "metadata": {},
   "source": [
    "We will be training on images and use a train/test \n",
    "split of 80/20 since our data set isnt particulairly large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f864db-a267-423f-a169-f30e903c44ba",
   "metadata": {},
   "source": [
    "REWRITE IN OWN WORDS\n",
    "\n",
    "Extract features for each frame:\n",
    "MFCCs (Mel-Frequency Cepstral Coefficients): Capture the short-term power spectrum of a sound in a way that mimics human hearing. They are excellent for representing the timbral or tonal quality of a sound. For each frame, you will get a vector of MFCCs (e.g., 13 or 20 coefficients).\n",
    "ZCR (Zero-Crossing Rate): Measures the rate at which the audio signal changes sign. It provides insight into the noisiness or harmonic content of a sound, with higher ZCRs indicating more high-frequency content. For each frame, you will get a single ZCR value.\n",
    "RMS (Root Mean Square): Represents the short-term loudness or energy of the audio signal. For each frame, you will get a single RMS value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badda36-3ba4-4e23-8791-948010b05c55",
   "metadata": {},
   "source": [
    "REWRITE IN OWN WORDS\n",
    "\n",
    "Concatenate the feature vectors: For each audio frame, you create a new, longer feature vector by combining the individual features. If you extract 13 MFCCs, 1 ZCR value, and 1 RMS value per frame, the new combined vector for that frame will have 15 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a4dd6-a8f6-4741-8229-1ac5a8ba1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to NumpyArrat with Keras, include third dimension for our CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b1629-81df-4f46-b03a-c7d759c5ff15",
   "metadata": {},
   "source": [
    "REWRITE IN OWN WORDS\n",
    "\n",
    "Create the final dataset: Your full dataset is a matrix where each row represents a frame from your audio files, and each column represents a specific feature or coefficient. This matrix serves as the input to your machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461cc00-14f3-408e-b7ef-5e5c81c96f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173036b-5848-41b5-a8e1-8ccc147f88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model 1 (Without data augmentation)\n",
    "# build baseline model, epochs 20, early stopping, 0.25 dropout, optimizer: opt, metric: accuracy, activation: relu, and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e18cb5-9024-463b-8561-bf4c2f749f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calssifiaciton report\n",
    "# heatmap\n",
    "# true versus predicted so confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130f951-2dfa-4553-b7a2-8d79c4b91a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model 2 (Chose how to augment the data, not speed and pitch)\n",
    "# maybe change below:\n",
    "# build baseline model, epochs 30, early stopping, 0.25 dropout, optimizer: opt, metric: accuracy, activation: relu, and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ba23c-82f6-41f9-9f49-a17329175a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model 3 (Dont augment the data use refined modeling)\n",
    "maybe try Log-melspectogram featurization technique o\n",
    "# maybe change below:\n",
    "# build baseline model, epochs 40, early stopping, 0.25 dropout, optimizer: opt, metric: accuracy, activation: relu, and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67215ac2-cf56-497d-b149-02dbcb417592",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model 3 (Use refined modeling and augmetation, not speed and pitch)\n",
    "maybe try Log-melspectogram featurization technique or find another and \n",
    "# maybe change below:\n",
    "# build baseline model, epochs 40, early stopping, 0.25 dropout, optimizer: opt, metric: accuracy, activation: relu, and softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3ed47-5ffd-46b8-ba6c-d55087112bc4",
   "metadata": {},
   "source": [
    "\"SpecAugment is also a powerful technique that involves masking segments \n",
    "and frequency intervals in the audio spectrogram to improve robustness \n",
    "in noisy environments. Combining these methods can significantly enhance \n",
    "SER performance, though the optimal strategy often depends on the specific \n",
    "dataset and task.\"\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
